{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --quiet\n",
        "!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1 --index-url https://download.pytorch.org/whl/cu121 --quiet\n",
        "!pip install pyannote-core==5.0.0 pyannote-audio==3.1.1 pyannote-metrics==3.2.1 --quiet\n",
        "!pip install ffmpeg-python --quiet"
      ],
      "metadata": {
        "id": "ANK7j4NjvAB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "CLEAN_AUDIO_PATH = \"audios/code_switch_cleaned.wav\"\n",
        "\n",
        "os.makedirs(\"diarization_output\", exist_ok=True)\n",
        "os.makedirs(\"segments\", exist_ok=True)\n",
        "\n",
        "print(\"Using cleaned audio:\", CLEAN_AUDIO_PATH)"
      ],
      "metadata": {
        "id": "CFQLt0sOPxKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31e79cc4-1cee-4602-d0e0-f10866a45568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Using cleaned audio: audios/code_switch_cleaned.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyannote.audio import Pipeline\n",
        "import torch\n",
        "\n",
        "HUGGINGFACE_TOKEN = \"\"\n",
        "\n",
        "# pyannote/speaker-diarization (For English)\n",
        "# pyannote/speaker-diarization-3.1 (For Arabic)\n",
        "pipeline = Pipeline.from_pretrained(\n",
        "    \"pyannote/speaker-diarization\",\n",
        "    use_auth_token=HUGGINGFACE_TOKEN,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "pipeline.to(device)\n",
        "\n",
        "diarization = pipeline(CLEAN_AUDIO_PATH, num_speakers=2)\n",
        "print(\"Diarization complete.\")"
      ],
      "metadata": {
        "id": "hV5j7uTEP2Ul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf731ce0-c22a-4598-c8a7-288212b3cc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.migration.utils:Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.6.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../root/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
            "Model was trained with torch 1.10.0+cu102, yours is 2.3.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/hyperparams.yaml'\n",
            "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-ecapa-voxceleb' if not cached\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in /root/.cache/torch/pyannote/speechbrain.\n",
            "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/classifier.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt'\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /root/.cache/torch/pyannote/speechbrain/embedding_model.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /root/.cache/torch/pyannote/speechbrain/mean_var_norm_emb.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /root/.cache/torch/pyannote/speechbrain/classifier.ckpt\n",
            "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n",
            "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /root/.cache/torch/pyannote/speechbrain/label_encoder.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diarization complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments = []\n",
        "\n",
        "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
        "    segments.append({\n",
        "        \"speaker\": speaker,\n",
        "        \"start\": float(turn.start),\n",
        "        \"end\": float(turn.end)\n",
        "    })\n",
        "\n",
        "print(\"Number of raw diarized segments:\", len(segments))\n",
        "segments[0:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U6u2pctzP25E",
        "outputId": "5816fbc5-7a3d-4a4b-cf71-da731e6c643f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of raw diarized segments: 14\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'speaker': 'SPEAKER_01',\n",
              "  'start': 0.4863481228668942,\n",
              "  'end': 3.4215017064846416},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 3.7286689419795227,\n",
              "  'end': 7.431740614334471},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 8.694539249146757,\n",
              "  'end': 14.786689419795222},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 15.759385665529011,\n",
              "  'end': 17.994880546075084},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 18.592150170648466,\n",
              "  'end': 23.063139931740615},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 24.39419795221843,\n",
              "  'end': 24.428327645051194},\n",
              " {'speaker': 'SPEAKER_01',\n",
              "  'start': 24.428327645051194,\n",
              "  'end': 29.974402730375427},\n",
              " {'speaker': 'SPEAKER_01',\n",
              "  'start': 30.6740614334471,\n",
              "  'end': 30.998293515358363},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 30.691126279863482,\n",
              "  'end': 36.578498293515366},\n",
              " {'speaker': 'SPEAKER_01',\n",
              "  'start': 38.50682593856655,\n",
              "  'end': 44.496587030716725},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 44.496587030716725,\n",
              "  'end': 44.56484641638225},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 45.21331058020478,\n",
              "  'end': 50.65699658703072},\n",
              " {'speaker': 'SPEAKER_00',\n",
              "  'start': 51.970989761092156,\n",
              "  'end': 54.496587030716725},\n",
              " {'speaker': 'SPEAKER_01',\n",
              "  'start': 54.496587030716725,\n",
              "  'end': 55.02559726962457}]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_diarization(diarization, gap_threshold=0.5, min_duration=0.4):\n",
        "    merged_segments = []\n",
        "\n",
        "    for segment in diarization.itertracks(yield_label=True):\n",
        "        start, end, speaker = segment[0].start, segment[0].end, segment[2]\n",
        "\n",
        "        if merged_segments and merged_segments[-1]['speaker'] == speaker:\n",
        "            if start - merged_segments[-1]['end'] <= gap_threshold:\n",
        "                merged_segments[-1]['end'] = end\n",
        "            else:\n",
        "                merged_segments.append({'speaker': speaker, 'start': start, 'end': end})\n",
        "        else:\n",
        "            merged_segments.append({'speaker': speaker, 'start': start, 'end': end})\n",
        "\n",
        "    cleaned_segments = [\n",
        "        seg for seg in merged_segments\n",
        "        if seg['end'] - seg['start'] >= min_duration\n",
        "    ]\n",
        "\n",
        "    if cleaned_segments:\n",
        "        first_speaker = cleaned_segments[0]['speaker']\n",
        "        if first_speaker != 'SPEAKER_00':\n",
        "            for seg in cleaned_segments:\n",
        "                if seg['speaker'] == 'SPEAKER_00':\n",
        "                    seg['speaker'] = 'SPEAKER_01'\n",
        "                else:\n",
        "                    seg['speaker'] = 'SPEAKER_00'\n",
        "\n",
        "    return cleaned_segments\n",
        "\n",
        "cleaned_segments = clean_diarization(diarization)\n",
        "\n",
        "print(\"Number of cleaned segments:\", len(cleaned_segments))\n",
        "for seg in cleaned_segments:\n",
        "    print(seg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2QqKSmrjK9h",
        "outputId": "22173dee-f7f6-4726-b8e6-20753279300d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cleaned segments: 11\n",
            "{'speaker': 'SPEAKER_00', 'start': 0.4863481228668942, 'end': 3.4215017064846416}\n",
            "{'speaker': 'SPEAKER_01', 'start': 3.7286689419795227, 'end': 7.431740614334471}\n",
            "{'speaker': 'SPEAKER_01', 'start': 8.694539249146757, 'end': 14.786689419795222}\n",
            "{'speaker': 'SPEAKER_01', 'start': 15.759385665529011, 'end': 17.994880546075084}\n",
            "{'speaker': 'SPEAKER_01', 'start': 18.592150170648466, 'end': 23.063139931740615}\n",
            "{'speaker': 'SPEAKER_00', 'start': 24.428327645051194, 'end': 29.974402730375427}\n",
            "{'speaker': 'SPEAKER_01', 'start': 30.691126279863482, 'end': 36.578498293515366}\n",
            "{'speaker': 'SPEAKER_00', 'start': 38.50682593856655, 'end': 44.496587030716725}\n",
            "{'speaker': 'SPEAKER_01', 'start': 45.21331058020478, 'end': 50.65699658703072}\n",
            "{'speaker': 'SPEAKER_01', 'start': 51.970989761092156, 'end': 54.496587030716725}\n",
            "{'speaker': 'SPEAKER_00', 'start': 54.496587030716725, 'end': 55.02559726962457}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "json_path = \"diarization_output/code_switch.json\"\n",
        "\n",
        "with open(json_path, \"w\") as f:\n",
        "    json.dump(cleaned_segments, f, indent=4)\n",
        "\n",
        "print(\"Saved diarization JSON →\", json_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsdX7qbyQFB1",
        "outputId": "33c216c2-0d43-4af2-ef6f-073fb2b5cb15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved diarization JSON → diarization_output/model_2.1/code_switch.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "for i, seg in enumerate(segments):\n",
        "    start = seg[\"start\"]\n",
        "    end = seg[\"end\"]\n",
        "    speaker = seg[\"speaker\"]\n",
        "\n",
        "    out_path = f\"segments/code_switch_segments/seg_{i}_{speaker}.wav\"\n",
        "\n",
        "    (\n",
        "        ffmpeg\n",
        "        .input(CLEAN_AUDIO_PATH, ss=start, to=end)\n",
        "        .output(out_path, ac=1, ar=16000)\n",
        "        .overwrite_output()\n",
        "        .run(quiet=True)\n",
        "    )\n",
        "\n",
        "print(\"All segments saved to /segments folder.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqwCaIOkQHFy",
        "outputId": "5571ddf6-5dd7-4036-d3aa-a8d0b861cf1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All segments saved to /segments folder.\n"
          ]
        }
      ]
    }
  ]
}