{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate datasets torchaudio librosa torchcodec --quiet\n",
        "\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import pipeline\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
        "\n",
        "model_id = \"MohamedRashad/Arabic-Whisper-CodeSwitching-Edition\"\n",
        "\n",
        "pipe = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=model_id,\n",
        "    torch_dtype=torch_dtype,\n",
        "    device=device,\n",
        "    return_timestamps=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVqRkqK-HHQF",
        "outputId": "d9b84832-e583-4747-f876-d69a7fb622fb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Device set to use cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_audio(audio_path):\n",
        "    waveform, sr = torchaudio.load(audio_path)\n",
        "\n",
        "    if sr != 16000:\n",
        "        resampler = torchaudio.transforms.Resample(sr, 16000)\n",
        "        waveform = resampler(waveform)\n",
        "\n",
        "    if waveform.shape[0] > 1:\n",
        "        waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "    return waveform.squeeze().numpy()\n",
        "\n",
        "audio_input = prepare_audio(\"noise_arabic_cleaned.wav\")"
      ],
      "metadata": {
        "id": "v9h9zUYCIKOY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzd_J386HGa8",
        "outputId": "307275cc-cfd6-4a5e-a04d-69f3cdb2be78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "زيادت الصوت واضح و لا فيه دوشة لأ فيه شوية دوشة بس ده المطلوب عشان نشوف النظام هيدر يفهم الكلام و لا لأ صح لما جربته مرة لفترة كان بيقدر يرقط الكلام بس لو الدوشة زادت بيبدأ يغلط يعنى طيب نجرب دلوقت أنا هفضل أتكلم و أنت شغل المروح تمام و كده نشوف بقى هل الكلام هيفضل باين في النص و لا الدوشة تغطي عليه صوت المروح عالي جدا سمع؟أيوة سامع بس مافيش مشكلة احنا عايزين كده طيب قول اي جملة عادية كده زي الجلسة الجاية هنتكلم عن النتائج اللي طلعت الجلسة الجاية هنتكلم عن النتائج اللي طلعت و هنحاول نحسن الدقة في التسجيل كويس، دلوقت خليك بعيد عن الميكروفون و اتكلم تاني طيب الصوت كده واضح ولا واطي؟ لأ كده حلو جدا، عايزين نشوف بقى هل النظام هيقدر يفرق من الدوشة و الكلام؟ان شاء الله لو نجح فى التسجيل ده يبقى نموذج قوي جدا فى التعامل مع الدوش تمام يللا نسجل دلوقت و نشوف فى النتيجة بعدين زي الفور شكرا يا زيكى عفوا\n"
          ]
        }
      ],
      "source": [
        "tokenizer = pipe.tokenizer\n",
        "\n",
        "def transcribe_code_switched(audio_path):\n",
        "    audio_array = prepare_audio(audio_path)\n",
        "\n",
        "    # prompt = \"Transcribe ال audio ده ل عربي مصري بس ركز انك لازم تحافظ على الكلام ال English زي ما هو\"\n",
        "    # prompt = \"Transcribe this audio into English ONLY\"\n",
        "    prompt = \"طلع النص بتاع الصوت ده بالعربي المصري بس و بلاش اي لغة تانية \"\n",
        "    prompt_ids = tokenizer.get_prompt_ids(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    result = pipe(\n",
        "        audio_array,\n",
        "        return_timestamps=True,\n",
        "        generate_kwargs={\n",
        "            \"temperature\": 0,\n",
        "            \"language\": \"arabic\",\n",
        "            \"task\": \"transcribe\",\n",
        "            \"num_beams\": 5,\n",
        "            \"prompt_ids\": prompt_ids\n",
        "        }\n",
        "    )\n",
        "    return result\n",
        "\n",
        "result = transcribe_code_switched(\"noise_arabic_cleaned.wav\")\n",
        "\n",
        "print(result[\"text\"])"
      ]
    }
  ]
}